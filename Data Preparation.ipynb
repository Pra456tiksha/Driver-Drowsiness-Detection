import os
import shutil
import glob
from tqdm import tqdm   # Import tqdm for progress bar
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D
from tensorflow.keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator


from google.colab import drive
drive.mount('/content/drive')

Raw_DIR = r'/content/drive/MyDrive/Colab Notebooks/Raw_Data'
Prepared_DIR = r'/content/drive/MyDrive/Colab Notebooks/Prepared_Data'

# Create subfolders in Prepared_Data
os.makedirs(os.path.join(Prepared_DIR, 'Close Eyes'), exist_ok=True)
os.makedirs(os.path.join(Prepared_DIR, 'Open Eyes'), exist_ok=True)




# Walk through the Raw_DIR
for dirpath, dirname, filenames in os.walk(Raw_DIR):
    for i in tqdm([f for f in filenames if f.endswith('.jpg')]):
        if i.split('_')[1] == '0':
            shutil.copy(src=os.path.join(dirpath, i), dst=os.path.join(Prepared_DIR, 'Close Eyes', i))
        elif i.split('_')[1] == '1':
            shutil.copy(src=os.path.join(dirpath, i), dst=os.path.join(Prepared_DIR, 'Open Eyes', i))

# Walk through the Raw_DIR
for dirpath, _, filenames in os.walk(Raw_DIR):
    for filename in tqdm(filenames):
        if filename.endswith('.jpg'):
            if '0' in filename:
                shutil.copy(
                    src=os.path.join(dirpath, filename),
                    dst=os.path.join(Prepared_DIR, 'Close Eyes', filename)
                )
            elif '1' in filename:
                shutil.copy(
                    src=os.path.join(dirpath, filename),
                    dst=os.path.join(Prepared_DIR, 'Open Eyes', filename)
                )

# Paths to your Close Eyes and Open Eyes folders
close_eyes_dir = '/content/drive/MyDrive/Colab Notebooks/Prepared_Data/Close Eyes'
open_eyes_dir = '/content/drive/MyDrive/Colab Notebooks/Prepared_Data/Open Eyes'

# Paths to store the training and testing data
train_dir = '/content/drive/MyDrive/Colab Notebooks/Prepared_Data/Train'
test_dir = '/content/drive/MyDrive/Colab Notebooks/Prepared_Data/Test'

# Create train and test folders and subfolders
os.makedirs(os.path.join(train_dir, 'Close Eyes'), exist_ok=True)
os.makedirs(os.path.join(train_dir, 'Open Eyes'), exist_ok=True)
os.makedirs(os.path.join(test_dir, 'Close Eyes'), exist_ok=True)
os.makedirs(os.path.join(test_dir, 'Open Eyes'), exist_ok=True)

# List of image files in each category
close_eyes_files = os.listdir(close_eyes_dir)
open_eyes_files = os.listdir(open_eyes_dir)

# Split Close Eyes data
close_eyes_train, close_eyes_test = train_test_split(close_eyes_files, test_size=0.2, random_state=42)

# Split Open Eyes data
open_eyes_train, open_eyes_test = train_test_split(open_eyes_files, test_size=0.2, random_state=42)

# Move Close Eyes data to train and test folders
for file in close_eyes_train:
    src_path = os.path.join(close_eyes_dir, file)
    dst_path = os.path.join(train_dir, 'Close Eyes', file)
    shutil.copy(src_path, dst_path)

for file in close_eyes_test:
    src_path = os.path.join(close_eyes_dir, file)
    dst_path = os.path.join(test_dir, 'Close Eyes', file)
    shutil.copy(src_path, dst_path)

# Move Open Eyes data to train and test folders
for file in open_eyes_train:
    src_path = os.path.join(open_eyes_dir, file)
    dst_path = os.path.join(train_dir, 'Open Eyes', file)
    shutil.copy(src_path, dst_path)

for file in open_eyes_test:
    src_path = os.path.join(open_eyes_dir, file)
    dst_path = os.path.join(test_dir, 'Open Eyes', file)
    shutil.copy(src_path, dst_path)


batchsize=8

# Data augmentation configuration
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,        # Normalize pixel values
    rotation_range=0.2,        # Random rotation
    width_shift_range=0.2,    # Random horizontal shift
    height_shift_range=0.2,   # Random vertical shift
    shear_range=0.2,          # Shearing
    zoom_range=0.2,           # Random zoom
)

# Load and augment training data
train_generator = train_datagen.flow_from_directory(train_dir,target_size=(80, 80),  # Resize images to this size
                                                    batch_size=batchsize,class_mode='categorical')      # Assuming categorical classification

# Load testing data without augmentation
test_datagen = ImageDataGenerator(rescale=1.0/255.0)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(80, 80),
    batch_size=batchsize,
    class_mode='categorical'
)

# Create InceptionV3 model with pre-trained weights and without top layers
bmodel = InceptionV3(include_top=False, weights='imagenet', input_tensor=Input(shape=(80, 80, 3)))

# Build custom head on top of InceptionV3
hmodel = bmodel.output
hmodel = Flatten()(hmodel)
hmodel = Dense(64, activation='relu')(hmodel)
hmodel = Dropout(0.5)(hmodel)
hmodel = Dense(2, activation='softmax')(hmodel)  # Assuming 2 classes for classification

# Combine the base and head to create the final model
model = Model(inputs=bmodel.input, outputs=hmodel)

# Freeze the layers of the InceptionV3 base
for layer in bmodel.layers:
    layer.trainable = False



# Display the model summary
model.summary()

from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau

checkpoint = ModelCheckpoint(r'/content/drive/MyDrive/Colab Notebooks/Prepared_Data/models/model.h5',
                            monitor='val_loss',save_best_only=True,verbose=3,save_format='h5')

earlystop = EarlyStopping(monitor = 'val_loss', patience=7, verbose= 3, restore_best_weights=True)

learning_rate = ReduceLROnPlateau(monitor= 'val_loss', patience=3, verbose= 3, )

callbacks=[checkpoint,earlystop,learning_rate]


# Compile the model
model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])  # Use appropriate loss function for your task
# Train the model using the generators
model.fit_generator(
    train_generator,
    steps_per_epoch=train_generator.samples // batchsize,
    validation_data=test_generator,
    validation_steps=test_generator.samples // batchsize,
    epochs=10,  # Specify the number of epochs
    callbacks=callbacks)
# Save the trained model in .h5 format
model.save('/content/drive/MyDrive/Colab Notebooks/Prepared_Data/models/model.h5')


# Model Evaluation
# Evaluate the model using the train generator
loss, accuracy = model.evaluate_generator(train_generator,steps=train_generator.samples // batchsize)
print('Train accuracy:', accuracy)
print('Train loss:', loss)


# Evaluate the model using the test generator
loss, accuracy = model.evaluate_generator(test_generator, steps=test_generator.samples // batchsize)
print('Test accuracy:', accuracy)
print('Test loss:', loss)





